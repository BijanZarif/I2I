{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import os,sys,h5py,tempfile,re\n",
    "caffe_prefix = os.path.expandvars('$HOME/Code/caffe')\n",
    "caffe_root = os.path.expandvars('../../')\n",
    "caffe_pycaffe = os.path.join(caffe_root,'python')\n",
    "if not caffe_pycaffe in sys.path:\n",
    "    sys.path.append(caffe_pycaffe)\n",
    "import caffe\n",
    "from caffe.proto import caffe_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "\n",
    "npa=np.array\n",
    "def sigmoid(x):\n",
    "    return  1.0 / (1.0 + np.exp(-np.array(x,dtype=float)))\n",
    "\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_net(net_proto,caffeModel=None):\n",
    "    f = tempfile.NamedTemporaryFile(mode='w+', delete=False)\n",
    "    f.write(str(net_proto))\n",
    "    f.close()\n",
    "    if caffeModel is None:\n",
    "        return caffe.Net(f.name, caffe.TEST)\n",
    "    else:\n",
    "        return caffe.Net(f.name, caffeModel ,caffe.TEST)\n",
    "def load_proto(netFile):\n",
    "    net_proto = caffe_pb2.NetParameter()\n",
    "    text_format.Merge(open(netFile).read(),net_proto)\n",
    "    return net_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sitk_to_caffe(img,is_label=False,has_channels=False):\n",
    "    data = sitk.GetArrayFromImage(img)\n",
    "    if is_label:\n",
    "        data_0 = np.zeros_like(data,dtype=float)\n",
    "        data_0[np.nonzero(data)]=1.0\n",
    "        data = data_0\n",
    "    if has_channels:\n",
    "        data=data.transpose(3,0,1,2)\n",
    "        data=data[np.newaxis,...]\n",
    "    elif len(data.shape) < 4:\n",
    "        data= data[np.newaxis,np.newaxis,...]\n",
    "    return data\n",
    "def sitk_imginfo_dict(img,suffix=''):\n",
    "    imginfo=dict(info_size=img.GetSize(),\n",
    "    info_spacing=img.GetSpacing(),\n",
    "    info_origin=img.GetOrigin(),\n",
    "    info_direction=img.GetDirection(),\n",
    "    info_PixelID=img.GetPixelIDValue(),\n",
    "    info_ndshape=sitk.GetArrayFromImage(img).shape)\n",
    "    for k in imginfo.keys():\n",
    "        imginfo[k+suffix] = imginfo.pop(k)\n",
    "    return imginfo\n",
    "def dict_modkeys(d,prefix='',suffix=''):\n",
    "    for k in d.keys():\n",
    "        d[prefix+k+suffix] = d.pop(k)\n",
    "    return d\n",
    "def cast_float(img,rescale=True):\n",
    "    img=sitk.Cast(img,sitk.sitkFloat32)\n",
    "    if rescale:\n",
    "        return sitk.RescaleIntensity(img,0,255)\n",
    "    else:\n",
    "        return img\n",
    "def cast_uint8(img):\n",
    "    return sitk.Cast(img,sitk.sitkUInt8)\n",
    "def cast_int8(img):\n",
    "    return sitk.Cast(img,sitk.sitkInt8)\n",
    "def cast_int16(img):\n",
    "    return sitk.Cast(img,sitk.sitkInt16)\n",
    "def sitk_padflip_image(img,padpre,padpost,rescale=True,swp_idx=0,flip=True):\n",
    "    img = cast_float(img,rescale=rescale)\n",
    "    \n",
    "    img_nd = sitk.GetArrayFromImage(img)\n",
    "    if flip:\n",
    "        img_nd=img_nd.swapaxes(2-swp_idx,0)\n",
    "    img = sitk.GetImageFromArray(img_nd)\n",
    "    img = sitk.ConstantPad (img,padpre,padpost)\n",
    "    return img\n",
    "def write_h5_set(in_dict,h5_file,txtfile):\n",
    "    with h5py.File(h5_file, 'w') as f:\n",
    "        for k,v in in_dict.iteritems():\n",
    "            try:\n",
    "                f[k] = npa(v).astype(float)\n",
    "            except:\n",
    "                f[k] = npa(v)\n",
    "    with open(txtfile, 'a') as f:\n",
    "        f.write(h5_file + '\\n')\n",
    "def basename(fn):\n",
    "    return os.path.split(os.path.splitext(fn)[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputfile = '/home/AD/jmerkow/Dropbox/Data/vascular_data/OSMSC0087/OSMSC0087-cm.mha'\n",
    "netFile='../../models/I2INet3DMed/I2INet3DMed.prototxt'\n",
    "caffeModel='../../models/I2INet3DMed/I2INet3DMed.caffemodel'\n",
    "\n",
    "output_size = npa([96,96,48],dtype=int)[::-1]\n",
    "overlap = output_size/npa([8,8,8],dtype=int)[::-1]\n",
    "\n",
    "\n",
    "\n",
    "outputdir='./EdgeMaps/'\n",
    "tempdir='./tempdir/'\n",
    "\n",
    "roi=None\n",
    "fnbase=basename(inputfile)\n",
    "ov = int(((overlap[0]*(output_size[1]*output_size[2]))+\n",
    "     (overlap[1]*(output_size[0]*output_size[2]))+\n",
    "      (overlap[2]*(output_size[0]*output_size[1])))/float(np.prod(output_size))*100)\n",
    "gpu_id=0\n",
    "print(\"inputfile:\",inputfile,\"\\nbasename\",basename(inputfile))\n",
    "print(\"output_size:\",output_size,\"overlap:\",overlap,\"roi:\",roi if roi is not None else \"All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CalcuatePre(img,roi,output_size,overlap):\n",
    "\n",
    "    img_size=np.array(img.GetSize())\n",
    "    stride = output_size-overlap\n",
    "\n",
    "    if roi is None:\n",
    "        roi = npa((0,)*6)\n",
    "        roi[1::2]=img_size-1\n",
    "\n",
    "    roi_start = np.maximum(roi[0::2],0)\n",
    "    roi_end = np.minimum(roi[1::2],img_size)\n",
    "    roi_size = roi_end-roi_start\n",
    "\n",
    "    print(\"Region Start:\",roi_start,\"Region End:\",roi_end,\"Size\",roi_size)\n",
    "\n",
    "    num_stride= npa(np.ceil(roi_size/map(float,stride)),dtype=int)\n",
    "    last_one_start = (num_stride-1)*stride\n",
    "    last_one_end = last_one_start+output_size\n",
    "    roi_diff = np.maximum(last_one_end-roi_size,2)\n",
    "    nums_mod= (roi_diff)/2\n",
    "\n",
    "\n",
    "    roi_start = roi_start-nums_mod\n",
    "    roi_end = roi_end+nums_mod\n",
    "\n",
    "    padpre = [0-min(s,0) for s in roi_start]\n",
    "    padpost = [max(s,sz)-sz+1 for s,sz in zip (roi_end,img_size)]\n",
    "    start=roi_start+padpre\n",
    "\n",
    "    proc_dict=dict(padpre=padpre,\n",
    "                   padpost=padpost,\n",
    "                   stride=stride,\n",
    "                   roi_start=roi_start,\n",
    "                   roi_end=roi_end,\n",
    "                   roi_size=roi_size,\n",
    "                   roi=roi,\n",
    "                   overlap=overlap,\n",
    "                   start=start,\n",
    "                   num_stride=num_stride)\n",
    "    print(\"Old Size:\",npa(img_size))\n",
    "    print(\"New Size:\",npa(img_size)+npa(padpre)+npa(padpost))\n",
    "    \n",
    "    return proc_dict\n",
    "\n",
    "img=sitk.ReadImage(inputfile)\n",
    "proc_dict=CalcuatePre(img,roi,output_size,overlap)\n",
    "\n",
    "print(\"Files to write:\",np.prod(proc_dict['num_stride']))\n",
    "tempinputdir=os.path.join(tempdir,\"input\")\n",
    "outputbasename=os.path.join(tempinputdir,fnbase+\"-{:03d}-{:03d}-{:03d}.h5\")\n",
    "txtfile = os.path.join(tempinputdir,fnbase+\".txt\")\n",
    "if not os.path.exists(tempinputdir): os.makedirs(tempinputdir)\n",
    "print(outputbasename.format(0,0,0))\n",
    "print(txtfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def PreprocessImageAndWrite(img,outputname,txtfile,output_size,\n",
    "                    proc_dict,imginfo=dict()):\n",
    "    \n",
    "    padpre,padpost=proc_dict['padpre'],proc_dict['padpost'],\n",
    "    num_stride,stride=proc_dict['num_stride'],proc_dict['stride']\n",
    "    start=proc_dict['start']\n",
    "    \n",
    "    imginfo=sitk_imginfo_dict(img,'_org')\n",
    "   \n",
    "    imginfo.update(proc_dict)\n",
    "    \n",
    "    img = cast_float(img,rescale=False)\n",
    "    \n",
    "    temp_padpre,temp_padpost=npa([8, 8, 8]),npa([8, 8, 8])\n",
    "    \n",
    "    temp_padpre=np.minimum(temp_padpre,padpre)\n",
    "    temp_padpost=np.minimum(temp_padpost,padpost)\n",
    "    img = sitk_padflip_image(img,temp_padpre,temp_padpre,flip=False)\n",
    "    img = sitk.Normalize(img)*1.0\n",
    "    \n",
    "    \n",
    "    \n",
    "    ndimg=sitk.GetArrayFromImage(img)\n",
    "    print(\"Min\",ndimg.min(),\"Max:\",ndimg.max(),\"Mean:\",ndimg.mean(),\"STD:\",ndimg.std())\n",
    "    padpre-=temp_padpre\n",
    "    padpost-=temp_padpost\n",
    "    img = sitk_padflip_image(img,padpre,padpost,rescale=False,flip=False)\n",
    "    imginfo.update(sitk_imginfo_dict(img,'_pad'))\n",
    "    num_collect=np.prod(num_stride)\n",
    "        \n",
    "    open(txtfile,'w').close()\n",
    "    dot_on = 5\n",
    "    for i in range(0,num_stride[0]):\n",
    "            for j in range(0,num_stride[1]):\n",
    "                for k in range(0,num_stride[2]):\n",
    "                    idx = npa([i,j,k])*stride+start\n",
    "                    if not all(idx+output_size<=img.GetSize()):\n",
    "                        print([i,j,k],idx,start,idx+output_size,img.GetSize())\n",
    "                        raise\n",
    "\n",
    "                    roi_img = sitk.RegionOfInterest(img, output_size, idx)\n",
    "                    if not all(r==o for r,o in zip(roi_img.GetSize(),output_size)):\n",
    "                        print(roi_img.GetSize(),output_size)\n",
    "                    imginfo_roi=sitk_imginfo_dict(roi_img,'_roi')\n",
    "                    data = sitk_to_caffe(roi_img)\n",
    "                    in_dict=dict(image=data,\n",
    "                                info_outputsize=output_size,\n",
    "                                outputbasename=outputname,\n",
    "                                info_idx=idx,\n",
    "                                info_inds=[i,j,k])\n",
    "                    in_dict.update(imginfo)\n",
    "                    in_dict.update(imginfo_roi)\n",
    "                    h5_file=outputname.format(i,j,k)\n",
    "                    write_h5_set(in_dict,h5_file,txtfile)\n",
    "                    n=np.ravel_multi_index((i,j,k),num_stride)+1\n",
    "                    if n%dot_on==0 and n > 0: print('.',sep='',end='')\n",
    "                    if n%(dot_on*20)==0 and n > 0 or n==num_collect: print(' ', n,'/',num_collect,sep='')\n",
    "    print(\"Done!\",n)\n",
    "    return imginfo\n",
    "imginfo = PreprocessImageAndWrite(img,outputbasename,txtfile,output_size,\n",
    "                    proc_dict)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_proto=load_proto(netFile)\n",
    "net_proto.layer[0].hdf5_data_param.source = txtfile\n",
    "with open(txtfile,'r') as f:\n",
    "    img_files= [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tempoutdir=os.path.join(tempdir,\"output\")\n",
    "outtxtfile = os.path.join(tempoutdir,fnbase+\".txt\")\n",
    "if not os.path.exists(tempoutdir): os.makedirs(tempoutdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net=load_net(net_proto,caffeModel)\n",
    "with open(net_proto.layer[0].hdf5_data_param.source,'r') as f:\n",
    "    img_files= [line.strip() for line in f]\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(gpu_id)\n",
    "imgbname_last=''\n",
    "outtxtfiles=dict()\n",
    "dot_on=5\n",
    "num_collect= len(img_files)\n",
    "for n,img_name in enumerate(img_files):\n",
    "    h5name=img_name\n",
    "    imgbname=basename('-'.join(h5name.split('-')[:-3]))\n",
    "    output_subdir=os.path.join(tempoutdir,imgbname)\n",
    "    \n",
    "    h5name=img_name.replace(tempinputdir,output_subdir)\n",
    "    \n",
    "    if not os.path.exists(output_subdir): os.makedirs(output_subdir)\n",
    "    if imgbname not in outtxtfiles.keys(): outtxtfiles[imgbname]=outtxtfile\n",
    "\n",
    "    if(imgbname_last!=imgbname):\n",
    "        print(imgbname)\n",
    "    imgbname_last=imgbname\n",
    "    with h5py.File(img_name,'r') as f:\n",
    "        write_dict={k:npa(v) for k,v in f.iteritems() if k!='image'}\n",
    "    net.forward()\n",
    "    E=net.blobs['score1'].data\n",
    "    image=net.blobs['image'].data\n",
    "    in_dict=dict(E=E,**write_dict)\n",
    "    write_h5_set(in_dict,h5name,outtxtfile)\n",
    "    if n%dot_on==0 and n > 0: print('.',sep='',end='')\n",
    "    if n%(dot_on*20)==0 and n > 0 or n==num_collect: print(' ', n,'/',num_collect,sep='')\n",
    "    sys.stdout.flush()\n",
    "print(\"Done!\",n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for imgbname,outtxtfile in outtxtfiles.iteritems():\n",
    "    with open(outtxtfile,'r') as f:\n",
    "        allfiles={os.path.split(line.strip())[1]:line.strip() for line in f}\n",
    "    \n",
    "    with h5py.File(allfiles.itervalues().next(), 'r') as f:\n",
    "        img_size=npa(f['info_ndshape_org'])\n",
    "        img_size_pad=npa(f['info_ndshape_pad'])\n",
    "        padpre,padpost=npa(f['padpre']),npa(f['padpost'])\n",
    "        overlap,stride=npa(f['overlap']),npa(f['stride'])\n",
    "        regE_=os.path.split(outputbasename)[1].replace('{:03d}','(\\d*)').replace(fnbase,\"{:s}\")\n",
    "#         print(padpre,padpost,overlap,img_size,img_size_pad,)\n",
    "    \n",
    "    regE=regE_.format(imgbname)\n",
    "    print(regE)\n",
    "    regobj=re.compile(regE)\n",
    "    fn_nums=dict()\n",
    "    for fn in allfiles.keys():\n",
    "        m=regobj.search(fn)\n",
    "        if m:\n",
    "            fn_nums[fn]=map(int,m.groups())\n",
    "        else:\n",
    "            allfiles.pop(fn)\n",
    "        \n",
    "    fnarray=np.empty((npa(fn_nums.values()).max(axis=0)+1),dtype=object)\n",
    "    for fn,inds in fn_nums.iteritems():\n",
    "        fnarray[inds[0],inds[1],inds[2]]=fn\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "E=np.zeros(img_size_pad)+1\n",
    "zz=list()\n",
    "for i in range(fnarray.shape[0]):\n",
    "    Ej=list()\n",
    "    for j in range(fnarray.shape[1]):\n",
    "        Ek=list()\n",
    "        for k in range(fnarray.shape[2]):\n",
    "            if fnarray[i,j,k] is not None:\n",
    "                with h5py.File(os.path.join(allfiles[fnarray[i,j,k]]), 'r') as f:\n",
    "                    Ei=np.squeeze(np.array(f['E']))\n",
    "                    idx=npa(f['info_idx'])\n",
    "                    patch_start=(npa(f['info_idx'])+overlap/2)\n",
    "                    patch_end=(patch_start+stride)\n",
    "                    patch_start=patch_start[[2,1,0]]\n",
    "                    patch_end=patch_end[[2,1,0]]\n",
    "                    E_shape=E[patch_start[0]:patch_end[0],patch_start[1]:patch_end[1],patch_start[2]:patch_end[2]].shape\n",
    "                    Ei_shape=Ei[overlap[2]/2:-overlap[2]/2,overlap[1]/2:-overlap[1]/2,overlap[0]/2:-overlap[0]/2].shape\n",
    "                    if not all(r==o for r,o in zip(E_shape,Ei_shape)):\n",
    "                        print(\"start\",patch_start,\"stop\",patch_end,patch_end-patch_start)\n",
    "                        print(E_shape,Ei_shape)\n",
    "                        print()\n",
    "            \n",
    "                    E[patch_start[0]:patch_end[0],\n",
    "                      patch_start[1]:patch_end[1],\n",
    "                      patch_start[2]:patch_end[2]]=sigmoid(Ei)[overlap[2]/2:-overlap[2]/2,\n",
    "                                                      overlap[1]/2:-overlap[1]/2,\n",
    "                                                      overlap[0]/2:-overlap[0]/2]\n",
    "E=E[padpre[2]:-padpost[2],padpre[1]:-padpost[1],padpre[0]:-padpost[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "E=E-E.min()\n",
    "E.min()*255,E.max()*255\n",
    "itkE=cast_int16(sitk.GetImageFromArray(E*255))\n",
    "orgImg=sitk.ReadImage(inputfile)\n",
    "itkE.CopyInformation(orgImg)\n",
    "imgs=[dict(name='E',**sitk_imginfo_dict(itkE)),dict(name='img',**sitk_imginfo_dict(orgImg))]\n",
    "pandas.DataFrame(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(outputdir): os.makedirs(outputdir)\n",
    "outputname=os.path.join(outputdir,imgbname+'.mha')\n",
    "print(\"Writing file:\",outputname)\n",
    "sitk.WriteImage(itkE,outputname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
